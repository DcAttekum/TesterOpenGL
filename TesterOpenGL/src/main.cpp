#include <GLEW/glew.h>
#include <GLFW/glfw3.h>

#include <iostream>
#include <fstream>
#include <sstream>
#include <string>

// Easier way to handle opengl debugging. The GL_DEBUG and GL_RELEASE are defined in the 
// preprocessor (project->properties->c/c++). This way you won't get any debugging features
// in the release build. In the release version the GLCall still runs the code that it is
// given, but doesn't do any of the error checking. GLAssert does not do anything, so do not
// put code in there that still needs running.
#if GL_DEBUG == 1
#define GLAssert(x) if(x) __debugbreak()
#define GLCall(x)\
    GLClearError();\
    x;\
    GLAssert(GLLogError(#x, __FILE__, __LINE__));
#elif GL_RELEASE == 1
#define GLAssert(x) 
#define GLCall(x) x;
#endif

// To clean up any potential errors generated before calling the method you want to assert.
// This way you know that the errors you get back when you call GLLogError are the ones
// generated by the call you just did.
static void GLClearError() {
    while (glGetError() != GL_NO_ERROR);
}

// Usually called right after an opengl call to check for errors in debugging.
static bool GLLogError(const char* function, const char* file, int line) {
    bool result = false;

    while (GLenum error = glGetError() != GL_NO_ERROR) {
        std::cout << "OpenGL error [" << error << "] caused by: " << function << " on line " << line << " of [" << file << "]";
        result = true;
    }

    return result;
}

struct ShaderSource {
    std::string vertex;
    std::string fragment;
};

// ParseShader takes a file path that contains 2 sets of code for both a vertex shader and 
// a fragment shader. The code is put into a string stream and convert to a string
static ShaderSource ParseShader(const std::string& path) {
    enum class ShaderType {
        NONE = -1, 
        VERTEX = 0, 
        FRAGMENT = 1
    };

    ShaderType type = ShaderType::NONE;
    std::ifstream stream(path);
    std::stringstream ss[2];
    std::string line;

    while (getline(stream, line)) {
        if (line.find("#shader") != std::string::npos) {
            if (line.find("vertex") != std::string::npos) {
                type = ShaderType::VERTEX;
            }
            else if (line.find("fragment") != std::string::npos) {
                type = ShaderType::FRAGMENT;
            }
        }
        else if(type != ShaderType::NONE) {
            ss[(int)type] << line << '\n';
        }
    }

    return { ss[(int)ShaderType::VERTEX].str(), ss[(int)ShaderType::FRAGMENT].str() };
}

static unsigned int CompileShader(unsigned int type, const std::string& source) {
    const char* src = source.c_str();
    GLCall(unsigned int id = glCreateShader(type));

    GLCall(glShaderSource(id, 1, &src, nullptr));
    GLCall(glCompileShader(id));

    // Error handling
    int result;
    glGetShaderiv(id, GL_COMPILE_STATUS, &result);
    if (result == GL_FALSE) {
        int length;
        glGetShaderiv(id, GL_INFO_LOG_LENGTH, &length);

        // Alloca can allocate memory outside of the stack if too big, leading to stack overflow exceptions. When used in
        // small usecases (like here) it is fine though. malloc (on the heap) is preferred when dealing with bigger
        // chunks of memory.
        char* message = (char*)alloca(length * sizeof(char)); 
        glGetShaderInfoLog(id, length, &length, message);

        std::cout << "Error compiling shader [" << (type == GL_VERTEX_SHADER ? "vertex" : "fragment") << "]" << std::endl;
        std::cout << message << std::endl;
    }

    return id;
}

static unsigned int CreateShader(const std::string& vertexShader, const std::string& fragmentShader) {
    GLCall(unsigned int program = glCreateProgram());
    unsigned int vs = CompileShader(GL_VERTEX_SHADER, vertexShader);
    unsigned int fs = CompileShader(GL_FRAGMENT_SHADER, fragmentShader);

    GLCall(glAttachShader(program, vs));
    GLCall(glAttachShader(program, fs));
    GLCall(glLinkProgram(program));
    GLCall(glValidateProgram(program));

    GLCall(glDeleteShader(vs));
    GLCall(glDeleteShader(fs));

    return program;
}

int main(void) {
    GLFWwindow* window;

    /* Initialize the library */
    if (!glfwInit())
        std::cout << "There was a problem initializing glfw." << std::endl;

    /* Create a windowed mode window and its OpenGL context */
    window = glfwCreateWindow(640, 640, "Hello World", NULL, NULL);
    if (!window)
    {
        glfwTerminate();
        std::cout << "There was a problem creating a window." << std::endl;
    }

    /* Make the window's context current */
    glfwMakeContextCurrent(window);

    if (glewInit() != GLEW_OK) {
        std::cout << "There was a problem initializing glew." << std::endl;
    }

    // Vertexes for the buffer to use. Vertexes != position on screen.
    float positions[] = {
        -0.5f, -0.5f, // 0
         0.5f, -0.5f, // 1
         0.5f,  0.5f, // 2
        -0.5f,  0.5f  // 3
    };

    // Indices indicate which vertexes need to be drawn when. OpenGL can only draw triangles
    // by default, this means that for a square, you need to draw 2 triangles. It is very
    // inefficient to allocate memory for index 0 and 2 twice (these get used twice), so this
    // is where the indeces come in. 
    unsigned int indices[] = {
        0, 1, 2,
        2, 3, 0
    };

    // Vertex buffer
    unsigned int vBuffer;
    GLCall(glGenBuffers(1, &vBuffer));
    GLCall(glBindBuffer(GL_ARRAY_BUFFER, vBuffer));
    GLCall(glBufferData(GL_ARRAY_BUFFER, 8 * sizeof(float), positions, GL_STATIC_DRAW));

    GLCall(glEnableVertexAttribArray(0));
    GLCall(glVertexAttribPointer(0, 2, GL_FLOAT, GL_FALSE, 2 * sizeof(float), 0));

    // Index buffer
    unsigned int iBuffer;
    GLCall(glGenBuffers(1, &iBuffer));
    GLCall(glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, iBuffer));
    GLCall(glBufferData(GL_ELEMENT_ARRAY_BUFFER, 6 * sizeof(unsigned int), indices, GL_STATIC_DRAW));

    // Shaders are the programs that run on the gpu. Basically anything done in c++ runs on the cpu, 
    // this is why we need to use this special method. Otherwise everything would run on the cpu
    // instead of the gpu, where you would want the graphics processing to be done.
    ShaderSource src = ParseShader("res/shaders/Basic.shader");
    unsigned int shader = CreateShader(src.vertex, src.fragment);
    GLCall(glUseProgram(shader));

    // Uniforms are used to get data into a shader. The shaders are code that run on the gpu and to
    // get data in there, you use uniforms. It works sort of like a parameter. In this case for the 
    // color of what we are drawing. 
    GLCall(int location = glGetUniformLocation(shader, "u_Color"));
    GLAssert(location == -1);
    GLCall(glUniform4f(location, 1.0f, 0.5f, 0.8f, 1.0f));

    /* Loop until the user closes the window */
    while (!glfwWindowShouldClose(window))
    {
        /* Render here */
        GLCall(glClear(GL_COLOR_BUFFER_BIT));

        // Nullptr, because the index buffer is bound.
        GLCall(glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, nullptr));

        /* Swap front and back buffers */
        GLCall(glfwSwapBuffers(window));

        /* Poll for and process events */
        GLCall(glfwPollEvents());
    }

    GLCall(glDeleteProgram(shader));

    glfwTerminate();

    return 0;
}
